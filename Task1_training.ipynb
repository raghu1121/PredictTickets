{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please note this file can't be run directly until you implement the keras callbacks in the kerasregressor in scikit_learn.py, as shown below before training.__\n",
    "\n",
    "__Splitting the dataset into inputs and outputs.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>route_A-&gt;B</th>\n",
       "      <th>route_B-&gt;A</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day_of_year  hour  minute  day_of_week  holiday  route_A->B  \\\n",
       "0      1            1     8      15            3        1           0   \n",
       "1      1            1     9      15            3        1           1   \n",
       "2      1            1    10      15            3        1           0   \n",
       "3      1            1    11      45            3        1           1   \n",
       "4      1            1    12      45            3        1           0   \n",
       "\n",
       "   route_B->A  capacity  \n",
       "0           1      82.0  \n",
       "1           0      82.0  \n",
       "2           1      82.0  \n",
       "3           0      82.0  \n",
       "4           1      82.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "X = df.loc[:,:'capacity']\n",
    "Y = df.loc[:,'tickets_9_eur':'tickets_19_eur']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We split the inputs into train and test sets. It is not needed to split the outputs here, but it is automatically split later.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(X,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A standard scaler is being used only on certain features. Initially scaler is fit on training set and then applied on the test set. This scaler is pickled for later use. Here the train and test sets are again concatenated. This will be later split along with outputs.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "scaler = StandardScaler()\n",
    "X_train.loc[:,'month':'day_of_week'] = scaler.fit_transform(X_train.loc[:,'month':'day_of_week'])\n",
    "X_test.loc[:,'month':'day_of_week'] = scaler.transform(X_test.loc[:,'month':'day_of_week'])\n",
    "X_scaled = np.concatenate((X_train,X_test))\n",
    "joblib.dump(scaler,\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A simple neural network based on Keras, with dropouts to most layers to reduce overfitting.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "def mlp(dropout_rate=0.0,activation1='relu', activation2='relu', activation3='relu', activation4='relu',\n",
    "                       activation5='relu',activation6='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=len(X.columns), kernel_initializer='normal', activation=activation1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation=activation2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation=activation3))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation=activation4))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation=activation5))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation=activation6))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Implementing callbacks for earlystopping and checkpointing. Earlystopping ensures the model doesn't overfit.__\n",
    "__Please change the path if you have to rerun.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import  ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "outputFolder = 'models'\n",
    "filepath = outputFolder + \"/model-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto', period=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "callbacks_list = [earlystop, checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Setting up the parameter grid with activations, batchsize, dropout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation1 = ['elu','tanh','sigmoid']\n",
    "activation2 = ['elu', 'sigmoid','tanh']\n",
    "activation3 = ['elu', 'sigmoid','tanh']\n",
    "activation4 = ['elu', 'sigmoid','tanh']\n",
    "activation5 = ['elu', 'sigmoid','tanh']\n",
    "activation6 = ['elu', 'tanh', 'sigmoid']\n",
    "activation7 = ['relu']\n",
    "\n",
    "dropout_rate = [0.2,0.3]\n",
    "\n",
    "(row_size,_)=np.shape(X_train)\n",
    "min_bsize=int(row_size/100)\n",
    "batch_size=[min_bsize,2*min_bsize]\n",
    "\n",
    "param_grid = dict(activation1=activation1, activation2=activation2, activation3=activation3, activation4=activation4,\n",
    "                  activation5=activation5, activation6=activation6,  batch_size=batch_size, dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Here Kerasregressor is used to give it as input for the next step in the pipeline. Since the `validation_split` of 0.2 is being used here for early stopping we did not have a seperate train and test sets for inputs and outputs.__ \n",
    "\n",
    "__Unfortunately Kerasregressor doesn't support the callbacks yet. Please implement it based on this suggestion [here](https://github.com/keras-team/keras/issues/4278#issuecomment-258922449).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "estimator = KerasRegressor(build_fn=mlp, epochs=100,  verbose=2, validation_split=0.2,\n",
    "                           callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__using scikit learns `GridSearchCV` to iterate over paramgrid and use estimator defined above. Shufflesplit is used here skip the cross validation on several folds, rather only use the gridsearch feature.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,ShuffleSplit\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid, cv=ShuffleSplit(test_size=0.01, n_splits=1), scoring='neg_mean_absolute_error',verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Careful before starting training. This creates more than 2000 models due to checkpointing.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_scaled, Y.to_numpy())\n",
    "#type(Y.to_numpy()),type(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
